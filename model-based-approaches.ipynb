{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based Named Entity Recognition with spaCy\n",
    "\n",
    "In this notebook, we explore **model-based Named Entity Recognition (NER)** using spaCy, a state-of-the-art NLP library.\n",
    "\n",
    "## What is Model-based NER?\n",
    "\n",
    "Unlike lexicon-based approaches that use predefined word lists, model-based NER uses **machine learning models** trained on millions of texts to recognize entities based on:\n",
    "- **Context**: Words surrounding the entity\n",
    "- **Grammar**: Syntactic patterns\n",
    "- **Learned patterns**: Statistical patterns from training data\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this notebook, you will:\n",
    "- Understand how spaCy's NER model works\n",
    "- Apply spaCy to extract locations from EU Parliament speeches\n",
    "- Analyze the model's strengths and weaknesses\n",
    "- Compare model results with lexicon-based approaches\n",
    "\n",
    "## Structure\n",
    "\n",
    "1. Introduction to spaCy and NER\n",
    "2. Loading and exploring the spaCy model\n",
    "3. Extracting locations from speeches\n",
    "4. Analyzing results\n",
    "5. Error analysis and model limitations\n",
    "6. Comparison with lexicon-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./.venv/lib/python3.12/site-packages (3.8.11)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./.venv/lib/python3.12/site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in ./.venv/lib/python3.12/site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from spacy) (2.3.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->spacy) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Install packages (only needed the first time)\n",
    "!pip install spacy pandas tqdm matplotlib\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries successfully loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speeches: 1828\n",
      "\n",
      "Columns: ['speaker', 'text', 'party', 'date', 'agenda', 'speechnumber', 'procedure_ID', 'partyfacts_ID', 'period', 'chair', 'MEP', 'commission', 'written', 'multispeaker', 'link', 'translationInSpeech', 'translatedText']\n",
      "\n",
      "First rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>date</th>\n",
       "      <th>agenda</th>\n",
       "      <th>speechnumber</th>\n",
       "      <th>procedure_ID</th>\n",
       "      <th>partyfacts_ID</th>\n",
       "      <th>period</th>\n",
       "      <th>chair</th>\n",
       "      <th>MEP</th>\n",
       "      <th>commission</th>\n",
       "      <th>written</th>\n",
       "      <th>multispeaker</th>\n",
       "      <th>link</th>\n",
       "      <th>translationInSpeech</th>\n",
       "      <th>translatedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>President</td>\n",
       "      <td>I wish you an excellent good morning on this l...</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>2. Interinstitutional Body for Ethical Standar...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.europarl.europa.eu/doceo/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President</td>\n",
       "      <td>Dear colleagues, today marks the 50th annivers...</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>6. Statements by the President</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.europarl.europa.eu/doceo/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virginijus Sinkevičius</td>\n",
       "      <td>Mr President, honourable Members, dear rapport...</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>4. Framework of measures for strengthening Eur...</td>\n",
       "      <td>7</td>\n",
       "      <td>bill_165_ID bill_195_ID  bill_165_ID bill_195_ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.europarl.europa.eu/doceo/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anna Deparnay-Grunenberg</td>\n",
       "      <td>Mr President, I came to this House to be a voi...</td>\n",
       "      <td>Greens/EFA</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>4. Framework of measures for strengthening Eur...</td>\n",
       "      <td>9</td>\n",
       "      <td>bill_165_ID bill_195_ID  bill_165_ID bill_195_ID</td>\n",
       "      <td>6403.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.europarl.europa.eu/doceo/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seán Kelly</td>\n",
       "      <td>A Uachtaráin, teastaíonn uaim mo thacaíocht io...</td>\n",
       "      <td>PPE</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>4. Framework of measures for strengthening Eur...</td>\n",
       "      <td>24</td>\n",
       "      <td>bill_165_ID bill_195_ID  bill_165_ID bill_195_ID</td>\n",
       "      <td>6398.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.europarl.europa.eu/doceo/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    speaker  \\\n",
       "0                 President   \n",
       "1                 President   \n",
       "2    Virginijus Sinkevičius   \n",
       "3  Anna Deparnay-Grunenberg   \n",
       "4                Seán Kelly   \n",
       "\n",
       "                                                text       party        date  \\\n",
       "0  I wish you an excellent good morning on this l...           -  2024-04-25   \n",
       "1  Dear colleagues, today marks the 50th annivers...           -  2024-04-25   \n",
       "2  Mr President, honourable Members, dear rapport...           -  2024-04-25   \n",
       "3  Mr President, I came to this House to be a voi...  Greens/EFA  2024-04-25   \n",
       "4  A Uachtaráin, teastaíonn uaim mo thacaíocht io...         PPE  2024-04-25   \n",
       "\n",
       "                                              agenda  speechnumber  \\\n",
       "0  2. Interinstitutional Body for Ethical Standar...             1   \n",
       "1                     6. Statements by the President             1   \n",
       "2  4. Framework of measures for strengthening Eur...             7   \n",
       "3  4. Framework of measures for strengthening Eur...             9   \n",
       "4  4. Framework of measures for strengthening Eur...            24   \n",
       "\n",
       "                                        procedure_ID  partyfacts_ID  period  \\\n",
       "0                                                               NaN       9   \n",
       "1                                                               NaN       9   \n",
       "2   bill_165_ID bill_195_ID  bill_165_ID bill_195_ID            NaN       9   \n",
       "3   bill_165_ID bill_195_ID  bill_165_ID bill_195_ID         6403.0       9   \n",
       "4   bill_165_ID bill_195_ID  bill_165_ID bill_195_ID         6398.0       9   \n",
       "\n",
       "   chair    MEP  commission  written  multispeaker  \\\n",
       "0   True  False       False    False         False   \n",
       "1   True  False       False    False         False   \n",
       "2  False  False        True    False         False   \n",
       "3  False   True       False    False         False   \n",
       "4  False   True       False    False         False   \n",
       "\n",
       "                                                link  translationInSpeech  \\\n",
       "0  https://www.europarl.europa.eu/doceo/document/...                  NaN   \n",
       "1  https://www.europarl.europa.eu/doceo/document/...                  NaN   \n",
       "2  https://www.europarl.europa.eu/doceo/document/...                  NaN   \n",
       "3  https://www.europarl.europa.eu/doceo/document/...                  NaN   \n",
       "4  https://www.europarl.europa.eu/doceo/document/...                  NaN   \n",
       "\n",
       "   translatedText  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load EU Parliament speeches\n",
    "df = pd.read_csv('eu_speeches_2024_english.csv')\n",
    "\n",
    "print(f\"Number of speeches: {len(df)}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Understanding spaCy's NER Model\n",
    "\n",
    "## How does spaCy NER work?\n",
    "\n",
    "spaCy uses a **neural network** trained on millions of texts. The model:\n",
    "\n",
    "1. **Tokenizes** the text (splits into words)\n",
    "2. **Analyzes context** (looks at surrounding words)\n",
    "3. **Applies learned patterns** (from training data)\n",
    "4. **Predicts entity types** (PERSON, GPE, LOC, ORG, etc.)\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- ✓ **Context-aware**: Understands \"Paris Hilton\" (person) vs \"Paris, France\" (location)\n",
    "- ✓ **Generalizable**: Can recognize entities not in training data\n",
    "- ✓ **Multi-entity**: Recognizes many entity types simultaneously\n",
    "- ✗ **Black box**: Hard to understand why specific decisions were made\n",
    "- ✗ **Slower**: Requires more computational resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load spaCy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy model 'en_core_web_lg'...\n",
      "✓ Model loaded!\n",
      "\n",
      "Model information:\n",
      "  Language: en\n",
      "  Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "  Vectors: 684830 word vectors\n"
     ]
    }
   ],
   "source": [
    "# Load the English language model\n",
    "# Available models:\n",
    "# - en_core_web_sm: Small, fast, 12 MB\n",
    "# - en_core_web_md: Medium, balanced, 40 MB\n",
    "# - en_core_web_lg: Large, accurate, 560 MB\n",
    "\n",
    "MODEL_NAME = 'en_core_web_lg'\n",
    "\n",
    "print(f\"Loading spaCy model '{MODEL_NAME}'...\")\n",
    "nlp = spacy.load(MODEL_NAME)\n",
    "print(\"✓ Model loaded!\")\n",
    "\n",
    "# Model information\n",
    "print(f\"\\nModel information:\")\n",
    "print(f\"  Language: {nlp.meta['lang']}\")\n",
    "print(f\"  Pipeline: {nlp.pipe_names}\")\n",
    "print(f\"  Vectors: {nlp.meta.get('vectors', {}).get('keys', 0)} word vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Entity Types in spaCy\n",
    "\n",
    "spaCy recognizes 18 entity types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity types relevant for location extraction:\n",
      "\n",
      "  GPE: Countries, cities, states (Geopolitical Entity)\n",
      "  LOC: Non-GPE locations, mountain ranges, bodies of water\n",
      "\n",
      "We'll focus on these two types for finding locations!\n"
     ]
    }
   ],
   "source": [
    "# Display all entity types\n",
    "entity_types = {\n",
    "    'PERSON': 'People, including fictional',\n",
    "    'NORP': 'Nationalities or religious or political groups',\n",
    "    'FAC': 'Buildings, airports, highways, bridges, etc.',\n",
    "    'ORG': 'Companies, agencies, institutions, etc.',\n",
    "    'GPE': 'Countries, cities, states (Geopolitical Entity)',\n",
    "    'LOC': 'Non-GPE locations, mountain ranges, bodies of water',\n",
    "    'PRODUCT': 'Objects, vehicles, foods, etc.',\n",
    "    'EVENT': 'Named hurricanes, battles, wars, sports events, etc.',\n",
    "    'WORK_OF_ART': 'Titles of books, songs, etc.',\n",
    "    'LAW': 'Named documents made into laws',\n",
    "    'LANGUAGE': 'Any named language',\n",
    "    'DATE': 'Absolute or relative dates or periods',\n",
    "    'TIME': 'Times smaller than a day',\n",
    "    'PERCENT': 'Percentage',\n",
    "    'MONEY': 'Monetary values',\n",
    "    'QUANTITY': 'Measurements',\n",
    "    'ORDINAL': '\"first\", \"second\", etc.',\n",
    "    'CARDINAL': 'Numerals that do not fall under another type'\n",
    "}\n",
    "\n",
    "print(\"Entity types relevant for location extraction:\\n\")\n",
    "print(f\"  GPE: {entity_types['GPE']}\")\n",
    "print(f\"  LOC: {entity_types['LOC']}\")\n",
    "print(f\"\\nWe'll focus on these two types for finding locations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Testing the Model\n",
    "\n",
    "Let's see how spaCy performs on example sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing spaCy NER on example sentences:\n",
      "\n",
      "Sentence 1: In Paris and Berlin, we are discussing the future of Europe with partners from Madrid and Rome.\n",
      "\n",
      "Found entities:\n",
      "  'Paris' → GPE (Countries, cities, states (Geopolitical Entity))\n",
      "  'Berlin' → GPE (Countries, cities, states (Geopolitical Entity))\n",
      "  'Europe' → LOC (Non-GPE locations, mountain ranges, bodies of water)\n",
      "  'Madrid' → GPE (Countries, cities, states (Geopolitical Entity))\n",
      "  'Rome' → GPE (Countries, cities, states (Geopolitical Entity))\n",
      "\n",
      "Locations only (GPE + LOC):\n",
      "  ['Paris', 'Berlin', 'Europe', 'Madrid', 'Rome']\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Sentence 2: Apple CEO Tim Cook met with German Chancellor Olaf Scholz in Munich.\n",
      "\n",
      "Found entities:\n",
      "  'Apple' → ORG (Companies, agencies, institutions, etc.)\n",
      "  'Tim Cook' → PERSON (People, including fictional)\n",
      "  'German' → NORP (Nationalities or religious or political groups)\n",
      "  'Olaf Scholz' → PERSON (People, including fictional)\n",
      "  'Munich' → GPE (Countries, cities, states (Geopolitical Entity))\n",
      "\n",
      "Locations only (GPE + LOC):\n",
      "  ['Munich']\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Sentence 3: The Amazon rainforest and the Amazon company are both important topics.\n",
      "\n",
      "Found entities:\n",
      "  'Amazon' → ORG (Companies, agencies, institutions, etc.)\n",
      "  'Amazon' → ORG (Companies, agencies, institutions, etc.)\n",
      "\n",
      "Locations only (GPE + LOC):\n",
      "  []\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Sentence 4: President Biden visited Brussels for a NATO summit before traveling to Warsaw.\n",
      "\n",
      "Found entities:\n",
      "  'Biden' → PERSON (People, including fictional)\n",
      "  'Brussels' → GPE (Countries, cities, states (Geopolitical Entity))\n",
      "  'NATO' → ORG (Companies, agencies, institutions, etc.)\n",
      "  'Warsaw' → GPE (Countries, cities, states (Geopolitical Entity))\n",
      "\n",
      "Locations only (GPE + LOC):\n",
      "  ['Brussels', 'Warsaw']\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Observations:\n",
      "  - The model understands context (e.g., 'Apple' the company vs potential location)\n",
      "  - It distinguishes between different entity types\n",
      "  - It can handle multi-word entities ('Tim Cook', 'Olaf Scholz')\n"
     ]
    }
   ],
   "source": [
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"In Paris and Berlin, we are discussing the future of Europe with partners from Madrid and Rome.\",\n",
    "    \"Apple CEO Tim Cook met with German Chancellor Olaf Scholz in Munich.\",\n",
    "    \"The Amazon rainforest and the Amazon company are both important topics.\",\n",
    "    \"President Biden visited Brussels for a NATO summit before traveling to Warsaw.\"\n",
    "]\n",
    "\n",
    "print(\"Testing spaCy NER on example sentences:\\n\")\n",
    "\n",
    "for i, sentence in enumerate(test_sentences, 1):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    print(f\"Sentence {i}: {sentence}\")\n",
    "    print(f\"\\nFound entities:\")\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        print(f\"  '{ent.text}' → {ent.label_} ({entity_types.get(ent.label_, 'Unknown')})\")\n",
    "    \n",
    "    print(f\"\\nLocations only (GPE + LOC):\")\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]\n",
    "    print(f\"  {locations}\")\n",
    "    print(\"\\n\" + \"─\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"  - The model understands context (e.g., 'Apple' the company vs potential location)\")\n",
    "print(\"  - It distinguishes between different entity types\")\n",
    "print(\"  - It can handle multi-word entities ('Tim Cook', 'Olaf Scholz')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Applying spaCy to EU Parliament Speeches\n",
    "\n",
    "Now let's extract locations from real political speeches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define Location Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing extraction function:\n",
      "\n",
      "Text: The European Commission in Brussels works with member states like France, Germany, and Poland to address challenges facing the EU.\n",
      "\n",
      "Locations with types:\n",
      "  Brussels (GPE)\n",
      "  France (GPE)\n",
      "  Germany (GPE)\n",
      "  Poland (GPE)\n",
      "\n",
      "Location names only:\n",
      "  ['Brussels', 'France', 'Germany', 'Poland']\n"
     ]
    }
   ],
   "source": [
    "def find_locations_spacy(text, nlp_model, include_loc=True):\n",
    "    \"\"\"\n",
    "    Finds locations in a text using spaCy.\n",
    "    \n",
    "    Parameters:\n",
    "        text: The text to analyze\n",
    "        nlp_model: The loaded spaCy model\n",
    "        include_loc: Whether to include LOC entities (non-GPE locations)\n",
    "    \n",
    "    Return:\n",
    "        List of found locations with their types\n",
    "    \"\"\"\n",
    "    # Process text through model\n",
    "    doc = nlp_model(text)\n",
    "    \n",
    "    # Extract location entities\n",
    "    if include_loc:\n",
    "        locations = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]\n",
    "    else:\n",
    "        locations = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ == 'GPE']\n",
    "    \n",
    "    return locations\n",
    "\n",
    "def get_location_texts(text, nlp_model):\n",
    "    \"\"\"\n",
    "    Returns just the location names (without types).\n",
    "    \"\"\"\n",
    "    locations = find_locations_spacy(text, nlp_model)\n",
    "    return [loc[0] for loc in locations]\n",
    "\n",
    "# Test the function\n",
    "test_text = \"The European Commission in Brussels works with member states like France, Germany, and Poland to address challenges facing the EU.\"\n",
    "\n",
    "print(\"Testing extraction function:\\n\")\n",
    "print(f\"Text: {test_text}\\n\")\n",
    "\n",
    "locations_with_types = find_locations_spacy(test_text, nlp)\n",
    "print(\"Locations with types:\")\n",
    "for loc, typ in locations_with_types:\n",
    "    print(f\"  {loc} ({typ})\")\n",
    "\n",
    "print(f\"\\nLocation names only:\")\n",
    "print(f\"  {get_location_texts(test_text, nlp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Extract Locations from All Speeches\n",
    "\n",
    "**Note**: This will take several minutes (2-10 minutes depending on dataset size and computer speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting locations from all speeches with spaCy...\n",
      "Processing 1828 speeches (this may take 2-10 minutes)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing speeches: 100%|██████████| 1828/1828 [00:45<00:00, 40.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Extraction completed!\n",
      "\n",
      "Statistics:\n",
      "  Speeches with at least one location: 1297 of 1828\n",
      "  Average locations per speech: 3.69\n",
      "  Maximum locations in one speech: 54\n",
      "  Total unique locations found: 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting locations from all speeches with spaCy...\")\n",
    "print(f\"Processing {len(df)} speeches (this may take 2-10 minutes)\\n\")\n",
    "\n",
    "# Apply extraction to all speeches\n",
    "tqdm.pandas(desc=\"Processing speeches\")\n",
    "\n",
    "df['ner_spacy_detailed'] = df['text'].progress_apply(\n",
    "    lambda text: find_locations_spacy(text, nlp)\n",
    ")\n",
    "\n",
    "# Extract just the location names\n",
    "df['ner_spacy'] = df['ner_spacy_detailed'].apply(\n",
    "    lambda locs: [loc[0] for loc in locs]\n",
    ")\n",
    "\n",
    "# Count locations per speech\n",
    "df['ner_spacy_count'] = df['ner_spacy'].apply(len)\n",
    "\n",
    "print(\"\\n✓ Extraction completed!\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Speeches with at least one location: {(df['ner_spacy_count'] > 0).sum()} of {len(df)}\")\n",
    "print(f\"  Average locations per speech: {df['ner_spacy_count'].mean():.2f}\")\n",
    "print(f\"  Maximum locations in one speech: {df['ner_spacy_count'].max()}\")\n",
    "print(f\"  Total unique locations found: {len(set([loc for locs in df['ner_spacy'] for loc in locs]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Analyzing Results\n",
    "\n",
    "Let's explore what the model found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Most Frequently Mentioned Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most mentioned locations:\n",
      "\n",
      "   1. Europe                    (1153 mentions)\n",
      "   2. Ukraine                   (758 mentions)\n",
      "   3. Russia                    (501 mentions)\n",
      "   4. Israel                    (280 mentions)\n",
      "   5. Gaza                      (271 mentions)\n",
      "   6. Ireland                   (162 mentions)\n",
      "   7. US                        (121 mentions)\n",
      "   8. Iran                      (111 mentions)\n",
      "   9. Hungary                   (106 mentions)\n",
      "  10. China                     ( 98 mentions)\n",
      "  11. EUR                       ( 87 mentions)\n",
      "  12. the Member States         ( 74 mentions)\n",
      "  13. Armenia                   ( 71 mentions)\n",
      "  14. Finland                   ( 66 mentions)\n",
      "  15. Leyen                     ( 61 mentions)\n",
      "  16. Germany                   ( 56 mentions)\n",
      "  17. Serbia                    ( 56 mentions)\n",
      "  18. Romania                   ( 56 mentions)\n",
      "  19. Brussels                  ( 55 mentions)\n",
      "  20. Greece                    ( 55 mentions)\n"
     ]
    }
   ],
   "source": [
    "# Collect all locations\n",
    "all_locations_spacy = [loc for locs in df['ner_spacy'] for loc in locs]\n",
    "location_counts_spacy = Counter(all_locations_spacy)\n",
    "\n",
    "print(\"Top 20 most mentioned locations:\\n\")\n",
    "for i, (location, count) in enumerate(location_counts_spacy.most_common(20), 1):\n",
    "    print(f\"  {i:2d}. {location:25s} ({count:3d} mentions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Distribution by Entity Type\n",
    "\n",
    "Let's see the split between GPE (countries/cities) and LOC (other locations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution by entity type:\n",
      "\n",
      "  GPE (Geopolitical Entity): 5194 mentions\n",
      "    Examples: [('Ukraine', 758), ('Russia', 501), ('Israel', 280), ('Gaza', 271), ('Ireland', 162)]\n",
      "\n",
      "  LOC (Other Locations): 1549 mentions\n",
      "    Examples: [('Europe', 1153), ('the Middle East', 30), ('the Western Balkans', 25), ('Africa', 21), ('Horizon Europe', 21)]\n",
      "\n",
      "Observation: GPE typically includes countries and cities,\n",
      "   while LOC includes regions, bodies of water, etc.\n"
     ]
    }
   ],
   "source": [
    "# Collect all entities with types\n",
    "all_entities_detailed = [ent for ents in df['ner_spacy_detailed'] for ent in ents]\n",
    "\n",
    "# Count by type\n",
    "gpe_entities = [ent[0] for ent in all_entities_detailed if ent[1] == 'GPE']\n",
    "loc_entities = [ent[0] for ent in all_entities_detailed if ent[1] == 'LOC']\n",
    "\n",
    "print(\"Distribution by entity type:\\n\")\n",
    "print(f\"  GPE (Geopolitical Entity): {len(gpe_entities)} mentions\")\n",
    "print(f\"    Examples: {list(Counter(gpe_entities).most_common(5))}\")\n",
    "print()\n",
    "print(f\"  LOC (Other Locations): {len(loc_entities)} mentions\")\n",
    "print(f\"    Examples: {list(Counter(loc_entities).most_common(5))}\")\n",
    "print()\n",
    "print(f\"Observation: GPE typically includes countries and cities,\")\n",
    "print(f\"   while LOC includes regions, bodies of water, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Example Speeches\n",
    "\n",
    "Let's look at specific speeches in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SPEECH WITH MOST LOCATION MENTIONS\n",
      "================================================================================\n",
      "Speaker: Ursula von der Leyen\n",
      "Party: -\n",
      "Date: 2024-03-12\n",
      "Number of locations: 54\n",
      "\n",
      "Locations found: ['Ukraine', 'the Middle East', 'the Middle East', 'Cyprus', 'Gaza', 'Cyprus', 'the United\\xa0Arab Emirates', 'the United States', 'the United Kingdom', 'Larnaca', 'Gaza', 'Gaza', 'Gaza', 'Gaza', 'Gaza', 'The United States', 'The United\\xa0Arab Emirates', 'Cyprus', 'Larnaca', 'Cyprus', 'Jordan', 'Gaza', 'Gaza', 'EUR', 'Strip', 'Gaza', 'EUR', 'Israel', 'Gaza', 'Israel', 'Lebanon', 'Iran', 'Yemen', 'Russia', 'Ukraine', 'Iran', 'Russia', 'Gaza', 'the Member States', 'Gaza', 'the Western Balkans', 'the Western Balkans', 'the Western Balkans', 'Albania', 'North\\xa0Macedonia', 'Bosnia and Herzegovina', 'Bosnia and Herzegovina', 'Bosnia and Herzegovina', 'Bosnia and Herzegovina', 'Yugoslavia', 'Bosnia and Herzegovina', 'Bosnia and Herzegovina', 'Bosnia and Herzegovina', 'Europe']\n",
      "\n",
      "Text (first 500 characters):\n",
      "Madam President, dear Roberta, Minister, dear Hadja, honourable Members, indeed we are heading towards a packed European Council, with topics, as you said, from Ukraine to the Middle East, defence to enlargement. I want to focus on two topics today. One is the Middle East and the other one is enlargement. As we speak, a ship is setting sail from Cyprus to northern Gaza. It carries the most basic kind of humanitarian aid, which is also the most needed today: food – plain and simply, food – for a ...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Find speech with most locations\n",
    "max_locations_idx = df['ner_spacy_count'].idxmax()\n",
    "max_locations_speech = df.loc[max_locations_idx]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SPEECH WITH MOST LOCATION MENTIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Speaker: {max_locations_speech['speaker']}\")\n",
    "print(f\"Party: {max_locations_speech['party']}\")\n",
    "print(f\"Date: {max_locations_speech['date']}\")\n",
    "print(f\"Number of locations: {max_locations_speech['ner_spacy_count']}\")\n",
    "print(f\"\\nLocations found: {max_locations_speech['ner_spacy']}\")\n",
    "print(f\"\\nText (first 500 characters):\")\n",
    "print(max_locations_speech['text'][:500] + \"...\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DETAILED ANALYSIS: SPEECH #20\n",
      "================================================================================\n",
      "Speaker: Mick Wallace\n",
      "Party: The Left\n",
      "Date: 2024-04-25\n",
      "\n",
      "Text (first 400 characters):\n",
      "Madam President, when we talk about EU enlargement, including Ukrainian accession, the people of Europe and especially Ireland should be aware of exactly what it will mean. The cost of Ukrainian accession will be monumental. It will cost trillions to rebuild Ukraine, not the EUR 50 billion. That’s before we talk about the actual cost of enlargement. Ukraine and Moldova are three times poorer than ...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Locations found by spaCy:\n",
      "  • Europe                         [LOC]\n",
      "  • Ireland                        [GPE]\n",
      "  • Ukraine                        [GPE]\n",
      "  • Ukraine                        [GPE]\n",
      "  • Moldova                        [GPE]\n",
      "  • Bulgaria                       [GPE]\n",
      "  • Ireland                        [GPE]\n",
      "  • Ireland                        [GPE]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show a random speech with detailed entity information\n",
    "# ADJUSTMENT: Change this number to see different speeches\n",
    "EXAMPLE_INDEX = 20\n",
    "\n",
    "example_speech = df.iloc[EXAMPLE_INDEX]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"DETAILED ANALYSIS: SPEECH #{EXAMPLE_INDEX}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Speaker: {example_speech['speaker']}\")\n",
    "print(f\"Party: {example_speech['party']}\")\n",
    "print(f\"Date: {example_speech['date']}\")\n",
    "print(f\"\\nText (first 400 characters):\")\n",
    "print(example_speech['text'][:400] + \"...\")\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(f\"\\nLocations found by spaCy:\")\n",
    "for loc, typ in example_speech['ner_spacy_detailed']:\n",
    "    print(f\"  • {loc:30s} [{typ}]\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Error Analysis\n",
    "\n",
    "No model is perfect. Let's examine potential errors and limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Error Patterns\n",
    "\n",
    "Let's identify common types of errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common types of NER errors:\n",
      "\n",
      "1. AMBIGUOUS WORDS:\n",
      "   Words that can be locations OR other things:\n",
      "     - 'Council': 1 mentions\n",
      "       (Could be: location, organization, or institution)\n",
      "\n",
      "2. PARTIAL NAMES:\n",
      "   Sometimes only part of a location name is extracted:\n",
      "     - 'North' instead of 'North Korea'\n",
      "     - 'United' instead of 'United States'\n",
      "\n",
      "3. ADJECTIVES AS LOCATIONS:\n",
      "   Adjectives derived from place names:\n",
      "     - 'European' (adjective) vs 'Europe' (location)\n",
      "     - 'American' (adjective) vs 'America' (location)\n",
      "\n",
      "These errors occur because the model:\n",
      "   - Relies on statistical patterns, not perfect understanding\n",
      "   - Trained on general text, not specifically on political speeches\n",
      "   - Cannot always distinguish between different meanings\n"
     ]
    }
   ],
   "source": [
    "print(\"Common types of NER errors:\\n\")\n",
    "\n",
    "print(\"1. AMBIGUOUS WORDS:\")\n",
    "print(\"   Words that can be locations OR other things:\")\n",
    "ambiguous_examples = ['Union', 'Parliament', 'Council', 'Commission', 'Court']\n",
    "for word in ambiguous_examples:\n",
    "    if word in location_counts_spacy:\n",
    "        print(f\"     - '{word}': {location_counts_spacy[word]} mentions\")\n",
    "        print(f\"       (Could be: location, organization, or institution)\")\n",
    "\n",
    "print(\"\\n2. PARTIAL NAMES:\")\n",
    "print(\"   Sometimes only part of a location name is extracted:\")\n",
    "print(\"     - 'North' instead of 'North Korea'\")\n",
    "print(\"     - 'United' instead of 'United States'\")\n",
    "\n",
    "print(\"\\n3. ADJECTIVES AS LOCATIONS:\")\n",
    "print(\"   Adjectives derived from place names:\")\n",
    "print(\"     - 'European' (adjective) vs 'Europe' (location)\")\n",
    "print(\"     - 'American' (adjective) vs 'America' (location)\")\n",
    "\n",
    "print(\"\\nThese errors occur because the model:\")\n",
    "print(\"   - Relies on statistical patterns, not perfect understanding\")\n",
    "print(\"   - Trained on general text, not specifically on political speeches\")\n",
    "print(\"   - Cannot always distinguish between different meanings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Comparison with Lexicon-based Approach\n",
    "\n",
    "Let's compare spaCy with a simple lexicon-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Create Simple Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created lexicon with 77 locations\n",
      "\n",
      "Examples: ['Germany', 'Belgium', 'Bavaria', 'United Kingdom', 'Dublin', 'Hamburg', 'London', 'Latvia', 'Amsterdam', 'Britain']\n"
     ]
    }
   ],
   "source": [
    "# Create a simple location lexicon\n",
    "european_locations = {\n",
    "    # EU Countries\n",
    "    'Germany', 'France', 'Italy', 'Spain', 'Poland', 'Romania',\n",
    "    'Netherlands', 'Belgium', 'Greece', 'Portugal', 'Sweden',\n",
    "    'Hungary', 'Austria', 'Bulgaria', 'Denmark', 'Finland',\n",
    "    'Slovakia', 'Ireland', 'Croatia', 'Slovenia', 'Lithuania',\n",
    "    'Latvia', 'Estonia', 'Cyprus', 'Malta', 'Luxembourg',\n",
    "    \n",
    "    # Major capitals\n",
    "    'Paris', 'Berlin', 'Rome', 'Madrid', 'Warsaw', 'Brussels',\n",
    "    'Vienna', 'Athens', 'Lisbon', 'Budapest', 'Prague', 'Stockholm',\n",
    "    'Amsterdam', 'Copenhagen', 'Dublin', 'Helsinki', 'Bucharest',\n",
    "    \n",
    "    # Other important cities\n",
    "    'Barcelona', 'Milan', 'Munich', 'Hamburg', 'Lyon', 'Marseille',\n",
    "    'Manchester', 'Birmingham', 'Glasgow', 'Edinburgh',\n",
    "    \n",
    "    # Regions\n",
    "    'Europe', 'Catalonia', 'Bavaria', 'Andalusia', 'Tuscany',\n",
    "    'Flanders', 'Scotland', 'Wales',\n",
    "    \n",
    "    # Non-EU but commonly mentioned\n",
    "    'UK', 'United Kingdom', 'Britain', 'England', 'London',\n",
    "    'Ukraine', 'Russia', 'Moscow', 'Kyiv', 'Switzerland',\n",
    "    'Norway', 'Turkey', 'USA', 'United States', 'America', 'China'\n",
    "}\n",
    "\n",
    "locations_lower = {loc.lower(): loc for loc in european_locations}\n",
    "\n",
    "print(f\"✓ Created lexicon with {len(european_locations)} locations\")\n",
    "print(f\"\\nExamples: {list(european_locations)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying lexicon-based approach...\n",
      "✓ Lexicon-based extraction completed!\n"
     ]
    }
   ],
   "source": [
    "# Lexicon-based extraction function\n",
    "def find_locations_lexicon(text, location_dict):\n",
    "    \"\"\"\n",
    "    Simple lexicon-based location extraction.\n",
    "    \"\"\"\n",
    "    found_locations = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for word in words:\n",
    "        word_clean = word.strip('.,;:!?()[]\"\\'')\n",
    "        if word_clean.lower() in location_dict:\n",
    "            found_locations.append(location_dict[word_clean.lower()])\n",
    "    \n",
    "    return found_locations\n",
    "\n",
    "# Apply lexicon approach\n",
    "print(\"Applying lexicon-based approach...\")\n",
    "df['ner_lexicon'] = df['text'].apply(\n",
    "    lambda text: find_locations_lexicon(text, locations_lower)\n",
    ")\n",
    "df['ner_lexicon_count'] = df['ner_lexicon'].apply(len)\n",
    "\n",
    "print(\"✓ Lexicon-based extraction completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Direct Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARISON: spaCy vs Lexicon\n",
      "================================================================================\n",
      "\n",
      "Quantitative Comparison:\n",
      "  Lexicon approach:\n",
      "    - Average locations per speech: 1.88\n",
      "    - Total unique locations: 63\n",
      "    - Total mentions: 3445\n",
      "\n",
      "  spaCy approach:\n",
      "    - Average locations per speech: 3.69\n",
      "    - Total unique locations: 580\n",
      "    - Total mentions: 6743\n",
      "\n",
      "Overlap Analysis:\n",
      "  Locations found by both methods: 61\n",
      "  Only found by spaCy: 519\n",
      "  Only found by Lexicon: 2\n",
      "\n",
      "Overlap percentage: 10.5%\n"
     ]
    }
   ],
   "source": [
    "# Collect all locations from both methods\n",
    "all_locations_lexicon = [loc for locs in df['ner_lexicon'] for loc in locs]\n",
    "\n",
    "# Calculate overlaps\n",
    "set_spacy = set(all_locations_spacy)\n",
    "set_lexicon = set(all_locations_lexicon)\n",
    "\n",
    "only_spacy = set_spacy - set_lexicon\n",
    "only_lexicon = set_lexicon - set_spacy\n",
    "both = set_spacy & set_lexicon\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARISON: spaCy vs Lexicon\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nQuantitative Comparison:\")\n",
    "print(f\"  Lexicon approach:\")\n",
    "print(f\"    - Average locations per speech: {df['ner_lexicon_count'].mean():.2f}\")\n",
    "print(f\"    - Total unique locations: {len(set_lexicon)}\")\n",
    "print(f\"    - Total mentions: {len(all_locations_lexicon)}\")\n",
    "\n",
    "print(f\"\\n  spaCy approach:\")\n",
    "print(f\"    - Average locations per speech: {df['ner_spacy_count'].mean():.2f}\")\n",
    "print(f\"    - Total unique locations: {len(set_spacy)}\")\n",
    "print(f\"    - Total mentions: {len(all_locations_spacy)}\")\n",
    "\n",
    "print(f\"\\nOverlap Analysis:\")\n",
    "print(f\"  Locations found by both methods: {len(both)}\")\n",
    "print(f\"  Only found by spaCy: {len(only_spacy)}\")\n",
    "print(f\"  Only found by Lexicon: {len(only_lexicon)}\")\n",
    "\n",
    "print(f\"\\nOverlap percentage: {len(both) / len(set_spacy | set_lexicon) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations found ONLY by spaCy (sample of 30):\n",
      "\n",
      "   1. Alabama                        (1 mentions)\n",
      "   2. Americas                       (2 mentions)\n",
      "   3. Bangladesh                     (1 mentions)\n",
      "   4. Bosnia-Herzegovina             (2 mentions)\n",
      "   5. Christ                         (1 mentions)\n",
      "   6. ENVI                           (1 mentions)\n",
      "   7. Horizon Europe                 (21 mentions)\n",
      "   8. Ilan                           (1 mentions)\n",
      "   9. Iohannis                       (2 mentions)\n",
      "  10. Iran                           (111 mentions)\n",
      "  11. Lebanon                        (8 mentions)\n",
      "  12. Moldova                        (19 mentions)\n",
      "  13. Mosul                          (4 mentions)\n",
      "  14. North Macedonia                (3 mentions)\n",
      "  15. Pirates                        (1 mentions)\n",
      "  16. Sie                            (1 mentions)\n",
      "  17. Svenja                         (1 mentions)\n",
      "  18. Tibet                          (2 mentions)\n",
      "  19. Uganda                         (3 mentions)\n",
      "  20. Ukrainian                      (1 mentions)\n",
      "  21. Uyghurs                        (2 mentions)\n",
      "  22. Vučić                          (5 mentions)\n",
      "  23. Waterford                      (2 mentions)\n",
      "  24. West Bank                      (2 mentions)\n",
      "  25. Western Balkan                 (7 mentions)\n",
      "  26. fl                             (2 mentions)\n",
      "  27. flimkien                       (1 mentions)\n",
      "  28. the Czech Republic             (3 mentions)\n",
      "  29. the Red Square                 (1 mentions)\n",
      "  30. the Russian Federation         (9 mentions)\n",
      "\n",
      "These might be:\n",
      "   ✓ Real locations not in our lexicon (shows model's generalization)\n",
      "   ✗ False positives (shows model's errors)\n"
     ]
    }
   ],
   "source": [
    "# What did spaCy find that the lexicon didn't?\n",
    "print(\"Locations found ONLY by spaCy (sample of 30):\\n\")\n",
    "sample_spacy_unique = list(only_spacy)[:30]\n",
    "for i, loc in enumerate(sorted(sample_spacy_unique), 1):\n",
    "    count = location_counts_spacy[loc]\n",
    "    print(f\"  {i:2d}. {loc:30s} ({count} mentions)\")\n",
    "\n",
    "print(f\"\\nThese might be:\")\n",
    "print(f\"   ✓ Real locations not in our lexicon (shows model's generalization)\")\n",
    "print(f\"   ✗ False positives (shows model's errors)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations found ONLY by Lexicon:\n",
      "\n",
      "   1. Barcelona                      (1 mentions)\n",
      "   2. England                        (1 mentions)\n",
      "\n",
      "These show:\n",
      "   - Locations the model missed (false negatives)\n",
      "   - Places where lexicon's simplicity is an advantage\n"
     ]
    }
   ],
   "source": [
    "# What did the lexicon find that spaCy didn't?\n",
    "location_counts_lexicon = Counter(all_locations_lexicon)\n",
    "\n",
    "print(\"Locations found ONLY by Lexicon:\\n\")\n",
    "for i, loc in enumerate(sorted(only_lexicon), 1):\n",
    "    count = location_counts_lexicon[loc]\n",
    "    print(f\"  {i:2d}. {loc:30s} ({count} mentions)\")\n",
    "\n",
    "print(f\"\\nThese show:\")\n",
    "print(f\"   - Locations the model missed (false negatives)\")\n",
    "print(f\"   - Places where lexicon's simplicity is an advantage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Example-by-Example Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare on a specific speech\n",
    "# ADJUSTMENT: Change this number to see different speeches\n",
    "COMPARE_INDEX = 5\n",
    "\n",
    "compare_speech = df.iloc[COMPARE_INDEX]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"SIDE-BY-SIDE COMPARISON: SPEECH #{COMPARE_INDEX}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Speaker: {compare_speech['speaker']}\")\n",
    "print(f\"Party: {compare_speech['party']}\")\n",
    "print(f\"\\nText (first 500 characters):\")\n",
    "print(compare_speech['text'][:500] + \"...\")\n",
    "\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(f\"\\nLexicon approach found {compare_speech['ner_lexicon_count']} locations:\")\n",
    "print(f\"   {compare_speech['ner_lexicon']}\")\n",
    "\n",
    "print(f\"\\nspaCy approach found {compare_speech['ner_spacy_count']} locations:\")\n",
    "print(f\"   {compare_speech['ner_spacy']}\")\n",
    "\n",
    "# Find differences\n",
    "set_lex = set(compare_speech['ner_lexicon'])\n",
    "set_spa = set(compare_speech['ner_spacy'])\n",
    "\n",
    "print(f\"\\nDifferences:\")\n",
    "print(f\"   Found by both: {set_lex & set_spa}\")\n",
    "print(f\"   Only by Lexicon: {set_lex - set_spa}\")\n",
    "print(f\"   Only by spaCy: {set_spa - set_lex}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Conclusions and Reflection\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### Advantages of Model-based NER (spaCy):\n",
    "\n",
    "✅ **Generalization**: Finds locations not in any predefined list\n",
    "✅ **Context awareness**: Distinguishes \"Paris Hilton\" from \"Paris, France\"\n",
    "✅ **No manual curation**: No need to maintain location lists\n",
    "✅ **Multi-word entities**: Handles \"United Kingdom\", \"New York\" correctly\n",
    "✅ **Multiple entity types**: Can extract persons, organizations, dates simultaneously\n",
    "\n",
    "### Disadvantages of Model-based NER:\n",
    "\n",
    "❌ **False positives**: May identify non-locations as locations\n",
    "❌ **Intransparent**: Hard to understand why specific decisions were made\n",
    "❌ **Computationally expensive**: Slower than lexicon lookup\n",
    "❌ **Domain sensitivity**: Trained on general text, may miss domain-specific terms\n",
    "❌ **No confidence scores**: Hard to filter uncertain predictions\n",
    "\n",
    "### When to Use Model-based NER:\n",
    "\n",
    "- ✓ When you need to find entities you haven't anticipated\n",
    "- ✓ When context is important for disambiguation\n",
    "- ✓ When you have diverse, natural language text\n",
    "- ✓ When you can tolerate some errors\n",
    "- ✓ When you have computational resources\n",
    "\n",
    "### When to Use Lexicon-based NER:\n",
    "\n",
    "- ✓ When you have a well-defined, limited domain\n",
    "- ✓ When transparency is critical\n",
    "- ✓ When speed is essential\n",
    "- ✓ When you need 100% precision on known terms\n",
    "- ✓ When computational resources are limited\n",
    "\n",
    "## Best Practice: Hybrid Approach\n",
    "\n",
    "In practice, the best solution is often a **hybrid approach**:\n",
    "\n",
    "1. Use spaCy to find candidate locations\n",
    "2. Filter results using a lexicon (keep only known locations)\n",
    "3. Review rare/uncertain entities manually\n",
    "4. Continuously update the lexicon based on findings\n",
    "\n",
    "This combines the **recall** (finding many entities) of models with the **precision** (avoiding errors) of lexicons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "1. **Accuracy vs Coverage**: Would you prefer a method that finds 90% of locations with 80% accuracy, or 60% of locations with 95% accuracy?\n",
    "\n",
    "2. **Domain Adaptation**: How could we improve spaCy's performance on EU Parliament speeches specifically?\n",
    "\n",
    "3. **Error Impact**: In what applications would false positives be worse than false negatives, and vice versa?\n",
    "\n",
    "4. **Explainability**: How important is it to know WHY a model made a specific decision?\n",
    "\n",
    "5. **Future Directions**: How might large language models (like GPT) change NER in the future?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
